{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/1/attribution_project/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 7\n",
    "criterion = 'r2' #'neg_mean_squared_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = ['RandomForestRegressor','LinearRegression','XGBRegressor','LGBMRegressor','CatBoostRegressor']\n",
    "encoders = ['OneHotEncoder', 'CatBoostEncoder', 'None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_selector(path, X_train, y_train, X_test, y_test, algorithm, encoder='None',\n",
    "                      categorical_vars=[], save=False):\n",
    "    \n",
    "    import category_encoders\n",
    "    \n",
    "    if encoder=='None':\n",
    "        return(X_train, X_test)\n",
    "    \n",
    "    elif encoder == 'CatBoostEncoder':\n",
    "        enc = category_encoders.cat_boost.CatBoostEncoder().fit(X_train,y_train)\n",
    "    elif encoder == 'OneHotEncoder':\n",
    "        \n",
    "        X = pd.concat([X_train, X_test])     \n",
    "        enc = category_encoders.one_hot.OneHotEncoder(cols=categorical_vars).fit(X)\n",
    "        X_encoded = enc.transform(X)\n",
    "        \n",
    "        if save: \n",
    "            enc_list_col = [m['mapping'].columns.to_list() for m in enc.mapping]\n",
    "            enc_list_col_ids = [[X_encoded.columns.to_list().index(col) for col in list_col] \n",
    "                                for list_col in enc_list_col]\n",
    "\n",
    "            pickle.dump(enc_list_col_ids, \n",
    "                        open(path + algorithm + '_' + encoder + '_enc_list_col_ids.pkl','wb'))\n",
    "\n",
    "            #enc.mapping\n",
    "            pickle.dump(enc, open(path + algorithm + '_' + encoder + '_enc.pkl','wb'))\n",
    "            \n",
    "\n",
    "    # transform the dataset\n",
    "    X_train_encoded = enc.transform(X_train)\n",
    "    X_test_encoded = enc.transform(X_test)\n",
    "    \n",
    "    return(X_train_encoded, X_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algorithm_selector(algorithm, encoder, categorical_vars=[], eval_metric='r2', \n",
    "                       params=None, random_state=7):\n",
    "\n",
    "    if algorithm == 'CatBoostRegressor':\n",
    "        from catboost import CatBoostRegressor\n",
    "        \n",
    "        if params is None:\n",
    "            \n",
    "            if encoder == 'None':\n",
    "                model = CatBoostRegressor(verbose=0, cat_features=categorical_vars)\n",
    "            else:\n",
    "                model = CatBoostRegressor(verbose=0)\n",
    "            \n",
    "            parameters = {'depth'         : [2,4,6,8,10,12,14],\n",
    "                          'iterations': [50,100,200,500,1000,1500]\n",
    "                                     }\n",
    "        else:\n",
    "            parameters = params\n",
    "\n",
    "            if encoder == 'None':\n",
    "                model = CatBoostRegressor(verbose=0, cat_features=categorical_vars, depth=params['depth'], \n",
    "                                          iterations=params['iterations'])\n",
    "            else:\n",
    "                model = CatBoostRegressor(verbose=0, depth=params['depth'], iterations=params['iterations'])\n",
    "                \n",
    "        parameters_disp = parameters.copy()\n",
    "        \n",
    "    elif algorithm == 'XGBRegressor':\n",
    "        from xgboost import XGBRegressor\n",
    "        \n",
    "        if params is None:\n",
    "            model = XGBRegressor()\n",
    "            parameters = {'max_depth'         : [2,4,6,8,10,12,14],\n",
    "                          'n_estimators': [50,100,200,500,1000,1500]}\n",
    "        else:\n",
    "            model = XGBRegressor(max_depth=params['max_depth'], n_estimators=params['n_estimators'])\n",
    "            parameters = params\n",
    "        \n",
    "        parameters_disp = parameters.copy()\n",
    "        \n",
    "    elif algorithm == 'LGBMRegressor':\n",
    "        from lightgbm import LGBMRegressor\n",
    "        \n",
    "        if params is None:\n",
    "            \n",
    "            if encoder == 'None':\n",
    "                model = LGBMRegressor()\n",
    "            else:\n",
    "                model = LGBMRegressor()\n",
    "                \n",
    "            parameters = {'max_depth'         : [2,4,6,8,10,12,14],\n",
    "                          'n_estimators': [50,100,200,500,1000,1500]}\n",
    "        else:\n",
    "            model = LGBMRegressor(max_depth=params['max_depth'], n_estimators=params['n_estimators'])\n",
    "            parameters = params           \n",
    "        \n",
    "        parameters_disp = parameters.copy()\n",
    "        \n",
    "    elif algorithm == 'RandomForestRegressor':\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        \n",
    "        if params is None:\n",
    "            model = RandomForestRegressor(random_state=random_state)\n",
    "            parameters = {'max_depth'         : [2,4,6,8,10,12,14],\n",
    "                          'n_estimators': [50,100,200,500,1000,1500]}\n",
    "        else:\n",
    "            model = RandomForestRegressor(max_depth=params['max_depth'], n_estimators=params['n_estimators'], \n",
    "                                          random_state=random_state)\n",
    "            parameters = params\n",
    "        \n",
    "        parameters_disp = parameters.copy()\n",
    "        \n",
    "    elif algorithm == 'LinearRegression':\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        model = LinearRegression()\n",
    "        \n",
    "        parameters = None\n",
    "        parameters_disp = None \n",
    "        \n",
    "    return(model,parameters,parameters_disp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid_search_scorers(cv_results, grid_param_1, grid_param_2, name_param_1, name_param_2,\n",
    "                             metric='mean', scorer='r2' ):\n",
    "\n",
    "    if scorer == 'r2':\n",
    "        scorer_label = 'r-square'\n",
    "    elif scorer == 'neg_mean_squared_error':\n",
    "        scorer_label = 'MSE'\n",
    "    \n",
    "    _, ax = plt.subplots(1,1)\n",
    "\n",
    "    if metric == 'std':\n",
    "        # Get Test Scores std and for each grid search\n",
    "        scores_std = cv_results['std_test_'+scorer]\n",
    "        s=[]\n",
    "        for i in range(len(grid_param_2)):\n",
    "            l = scores_std[i::len(grid_param_2)]\n",
    "            s.append(l)\n",
    "        scores_std = np.array(s)\n",
    "        \n",
    "        for idx, val in enumerate(grid_param_2):\n",
    "            ax.plot(grid_param_1, scores_std[idx,:], '-o', label= name_param_2 + ': ' + str(val))\n",
    " \n",
    "        ax.set_ylabel('CV test ' + scorer_label + ' score SD', fontsize=16)\n",
    "    \n",
    "    else:\n",
    "        # Get Test Scores mean and for each grid search\n",
    "        scores_mean = cv_results['mean_test_'+scorer]\n",
    "        s=[]\n",
    "        for i in range(len(grid_param_2)):\n",
    "            l = scores_mean[i::len(grid_param_2)]\n",
    "            if scorer == 'neg_mean_squared_error':\n",
    "                l =  [abs(el) for el in l]\n",
    "            s.append(l)\n",
    "        scores_mean = np.array(s)\n",
    "        \n",
    "        for idx, val in enumerate(grid_param_2):\n",
    "            ax.plot(grid_param_1, scores_mean[idx,:], '-o', label= name_param_2 + ': ' + str(val))\n",
    "\n",
    "        ax.set_ylabel('CV mean test ' + scorer_label + ' score', fontsize=16)\n",
    "        \n",
    "    ax.set_title(\"Grid Search Scores\", fontsize=10, fontweight='bold')\n",
    "    ax.set_xlabel(name_param_1, fontsize=8)\n",
    "    ax.legend(loc=\"best\", fontsize=12, framealpha=1)\n",
    "    ax.grid('on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_combination(path, algorithm, encoder, X_train, X_test, y_train, y_test, cv, categorical_vars, \n",
    "                    criterion='r2', save=False, random_state=7):\n",
    "\n",
    "    path_performance = path + 'performance/'  + criterion + '/' + algorithm + '_' + encoder + '_'\n",
    "    \n",
    "    results = dict()\n",
    "    results['algorithm'] = algorithm\n",
    "    results['encoder'] = encoder\n",
    "    results1 = dict()\n",
    "\n",
    "    (X_train, X_test) = encoding_selector(path, X_train, y_train, X_test, y_test, algorithm, encoder=encoder,\n",
    "                                          categorical_vars=categorical_vars, save=save)\n",
    "    \n",
    "    X_train_copy = X_train.copy()\n",
    "    X_test_copy = X_test.copy()\n",
    "    \n",
    "    X_train_copy['dataset']=1\n",
    "    X_test_copy['dataset']=2\n",
    "\n",
    "    X = pd.concat([X_train_copy, X_test_copy])\n",
    "    \n",
    "    if save:\n",
    "        pickle.dump(X, open(path + algorithm + '_' + encoder + '_X.pkl','wb'))\n",
    "        pickle.dump(X_train, open(path + algorithm + '_' + encoder + '_X_train.pkl','wb'))\n",
    "        pickle.dump(X_test, open(path + algorithm + '_' + encoder + '_X_test.pkl','wb'))\n",
    "\n",
    "    #algorithm setup\n",
    "    model,parameters,parameters_disp = algorithm_selector(algorithm, encoder, \n",
    "                                                          categorical_vars=categorical_vars,\n",
    "                                                          eval_metric=criterion, random_state=random_state)\n",
    "    if algorithm != 'LinearRegression':\n",
    "        param_names = list(parameters.keys())\n",
    "\n",
    "    #the learning process\n",
    "    from sklearn import datasets\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "    scoring = {'r2', 'neg_mean_squared_error'}\n",
    "\n",
    "    #linear regression\n",
    "    if parameters==None:\n",
    "        from sklearn.model_selection import cross_validate\n",
    "        CV_scores = cross_validate(model, X_train, y_train, cv=cv, scoring=scoring)\n",
    "        \n",
    "        results['CV R2'] = np.mean(list(CV_scores['test_r2']))\n",
    "        results['CV R2 STD'] = np.std(list(CV_scores['test_r2']))\n",
    "        results['CV MSE'] = abs(np.mean(list(CV_scores['test_neg_mean_squared_error'])))\n",
    "        results['CV MSE STD'] = np.std(list(CV_scores['test_neg_mean_squared_error']))\n",
    "\n",
    "        \n",
    "    else:\n",
    "\n",
    "        grid = GridSearchCV(estimator= model, param_grid = parameters, scoring=scoring, refit=criterion, \n",
    "                            cv = cv, n_jobs=-1, return_train_score=True)\n",
    "        grid.fit(X_train, y_train)\n",
    "    \n",
    "        pickle.dump(grid, open(path + algorithm + '_' + encoder + '_grid.pkl','wb'))\n",
    "        \n",
    "        winner = np.argmax(grid.cv_results_['mean_test_' + criterion])\n",
    "        \n",
    "        params = {param_names[0]:grid.cv_results_['params'][winner][param_names[0]], \n",
    "                  param_names[1]:grid.cv_results_['params'][winner][param_names[1]]}\n",
    "\n",
    "        param_unifier = {'max_depth':'depth', 'depth':'depth', 'n_estimators':'n_estimators', \n",
    "                         'iterations':'iterations'}\n",
    "        \n",
    "        results[param_unifier[param_names[0]]] = grid.cv_results_['params'][winner][param_names[0]]\n",
    "        results[param_unifier[param_names[1]]] = grid.cv_results_['params'][winner][param_names[1]]\n",
    "\n",
    "        results['CV R2'] = grid.cv_results_['mean_test_r2'][winner]\n",
    "        results['CV R2 STD'] = grid.cv_results_['std_test_r2'][winner]\n",
    "        results['CV MSE'] = abs(grid.cv_results_['mean_test_neg_mean_squared_error'][winner])\n",
    "        results['CV MSE STD'] = abs(grid.cv_results_['std_test_neg_mean_squared_error'][winner])\n",
    "        \n",
    "        plt.clf()\n",
    "        plt.tight_layout()\n",
    "        plot_grid_search_scorers(grid.cv_results_, parameters_disp[param_names[0]], \n",
    "                                 parameters_disp[param_names[1]], param_names[0], param_names[1], \n",
    "                                 metric='mean', scorer='neg_mean_squared_error')\n",
    "        plt.savefig(path_performance + 'grid_MSE_mean.jpg')\n",
    "        \n",
    "        plt.clf()\n",
    "        plt.tight_layout()\n",
    "        plot_grid_search_scorers(grid.cv_results_, parameters_disp[param_names[0]],\n",
    "                                 parameters_disp[param_names[1]], param_names[0], param_names[1], \n",
    "                                 metric='std', scorer='neg_mean_squared_error')\n",
    "        plt.savefig(path_performance + 'grid_MSE_std.jpg')\n",
    "        \n",
    "        plt.clf()\n",
    "        plt.tight_layout()\n",
    "        plot_grid_search_scorers(grid.cv_results_, parameters_disp[param_names[0]], \n",
    "                                 parameters_disp[param_names[1]], param_names[0], param_names[1],\n",
    "                                 metric='mean', scorer='r2')\n",
    "        plt.savefig(path_performance + 'grid_R2_mean.jpg')\n",
    "        \n",
    "        plt.clf()\n",
    "        plt.tight_layout()\n",
    "        plot_grid_search_scorers(grid.cv_results_, parameters_disp[param_names[0]], \n",
    "                                 parameters_disp[param_names[1]], param_names[0], param_names[1],\n",
    "                                 metric='std', scorer='r2')\n",
    "        plt.savefig(path_performance + 'grid_R2_std.jpg')\n",
    "        \n",
    "        model,parameters,parameters_disp = algorithm_selector(algorithm,encoder,\n",
    "                                                              categorical_vars=categorical_vars,\n",
    "                                                              params=params)\n",
    "        \n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    results1['train_corr'] = np.corrcoef(y_train, y_train_pred)[0,1]\n",
    "    \n",
    "    y_test_pred = model.predict(X_test)\n",
    "    results1['test_corr'] = np.corrcoef(y_test, y_test_pred)[0,1]\n",
    "    \n",
    "    from catboost.utils import eval_metric\n",
    "    \n",
    "    results1['train R2'] = eval_metric(y_train, y_train_pred, 'R2')[0]\n",
    "    results1['test R2'] = eval_metric(list(y_test), list(y_test_pred), 'R2')[0]\n",
    "    \n",
    "    results1['train MSE'] = eval_metric(y_train, y_train_pred, 'RMSE')[0] **2\n",
    "    results1['test MSE'] = eval_metric(list(y_test), list(y_test_pred), 'RMSE')[0] **2\n",
    "\n",
    "    \n",
    "    if save: #and algorithm != 'LinearRegression':\n",
    "        pickle.dump(model, open(path + algorithm + '_' + encoder + '_model.pkl','wb'))\n",
    "        pickle.dump(y_test_pred, open(path + algorithm + '_' + encoder + '_y_test_pred.pkl','wb'))\n",
    "        pickle.dump(y_train_pred, open(path + algorithm + '_' + encoder + '_y_train_pred.pkl','wb'))\n",
    "    \n",
    "    \n",
    "    #analysing results\n",
    "    \n",
    "    path_performance_train = path + 'performance/'  + criterion + '/train/' + algorithm + '_' + encoder + '_'\n",
    "    path_performance_test = path + 'performance/'  + criterion + '/test/' + algorithm + '_' + encoder + '_'\n",
    "    \n",
    "    #train data\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.plot(y_train, y_train_pred, 'o', color='black')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path_performance_train + 'y_pred.jpg')\n",
    "\n",
    "    plt.clf()\n",
    "    plt.plot(y_train, y_train_pred-y_train, 'o', color='black')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path_performance_train + 'y_error.jpg')\n",
    "\n",
    "\n",
    "    MAPE_train = np.abs((y_train - y_train_pred) / y_train)\n",
    "    bul_train = np.isinf(MAPE_train)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.hist(MAPE_train[~bul_train])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path_performance_train + 'y_nonzero_pred.jpg')\n",
    "\n",
    "    plt.clf()\n",
    "    plt.hist(y_train_pred[bul_train])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path_performance_train + 'y_zero_pred.jpg')\n",
    "\n",
    "\n",
    "    #test data\n",
    "\n",
    "    plt.clf()\n",
    "    plt.plot(y_test, y_test_pred, 'o', color='black')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path_performance_test + 'y_pred.jpg')\n",
    "\n",
    "    plt.clf()\n",
    "    plt.plot(y_test, y_test_pred-y_test, 'o', color='black')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path_performance_test + 'y_error.jpg')\n",
    "\n",
    "\n",
    "    MAPE_test = np.abs((y_test - y_test_pred) / y_test)\n",
    "    bul_test = np.isinf(MAPE_test)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.hist(MAPE_test[~bul_test])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path_performance_test + 'y_nonzero_pred.jpg')\n",
    "\n",
    "    plt.clf()\n",
    "    plt.hist(y_test_pred[bul_test])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path_performance_test + 'y_zero_pred.jpg')\n",
    "    \n",
    "    \n",
    "    results1['MAPE_train_nonzero'] = np.mean(MAPE_train[~bul_train])\n",
    "    results1['MAPE_test_nonzero'] = np.mean(MAPE_test[~bul_test])\n",
    "        \n",
    "    results1['MAE_train_zero'] = np.mean(np.absolute(y_train_pred[bul_train]))\n",
    "    results1['MAE_test_zero'] = np.mean(np.absolute(y_test_pred[bul_test]))\n",
    "    \n",
    "    df_results1 = pd.DataFrame.from_dict([results1])\n",
    "    pickle.dump(df_results1, open(path_performance + 'results.pkl','wb'))\n",
    "    df_results1.columns = df_results1.columns.str.replace('_',' ')\n",
    "    df_results1.to_csv(path_performance + 'results.csv', index=False)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for m in [10,7,3]:\n",
    "\n",
    "    print('m ', m)\n",
    "\n",
    "    path_in = path + 'results/m' + str(m) + '/data/'\n",
    "    path_out = path + 'results/m' + str(m) + '/output/'\n",
    "\n",
    "    X_train = pickle.load(open(path_in + 'X_train.pkl','rb'))\n",
    "    y_train = pickle.load(open(path_in + 'y_train.pkl','rb'))\n",
    "\n",
    "    X_test = pickle.load(open(path_in + 'X_test.pkl','rb'))\n",
    "    y_test = pickle.load(open(path_in + 'y_test.pkl','rb'))\n",
    "\n",
    "    cv = pickle.load(open(path_in + 'cv.pkl','rb'))\n",
    "    categorical_vars = pickle.load(open(path_in + 'categorical_vars.pkl','rb'))\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for algorithm in algorithms:\n",
    "        for encoder in encoders:\n",
    "            if (encoder != 'None' or algorithm in ('LGBMRegressor', 'CatBoostRegressor')) and (encoder != 'CatBoostEncoder' \n",
    "                                                                                        or  algorithm != 'CatBoostRegressor'):\n",
    "                print(algorithm, encoder)\n",
    "                run_results = run_combination(path_out, algorithm, encoder, X_train, X_test, y_train, y_test,\n",
    "                                              cv, categorical_vars, criterion=criterion,\n",
    "                                              save=True, random_state=random_state)\n",
    "\n",
    "                results.append(run_results)\n",
    "\n",
    "\n",
    "    df_results = pd.DataFrame.from_dict(results)\n",
    "\n",
    "    #ordering the results\n",
    "    criterion2order = {'r2':'CV R2', 'neg_mean_squared_error':'CV MSE'}\n",
    "    order = criterion2order[criterion]\n",
    "\n",
    "    if criterion == 'neg_mean_squared_error':\n",
    "        df_results = df_results.sort_values(by=order, ascending=True)\n",
    "    else:\n",
    "        df_results = df_results.sort_values(by=order, ascending=False)\n",
    "\n",
    "    pickle.dump(df_results, open(path_out  + 'performance/' + criterion + '/df_results.pkl','wb'))\n",
    "\n",
    "    df_results.columns = df_results.columns.str.replace('_',' ')\n",
    "\n",
    "    df_results.to_csv(path_out + 'performance/' + criterion + '/results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
